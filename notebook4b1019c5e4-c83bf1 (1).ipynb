{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":82253,"databundleVersionId":8965849,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-28T19:34:18.532426Z","iopub.execute_input":"2024-06-28T19:34:18.533618Z","iopub.status.idle":"2024-06-28T19:34:19.865876Z","shell.execute_reply.started":"2024-06-28T19:34:18.533578Z","shell.execute_reply":"2024-06-28T19:34:19.864435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Replace 'filename.csv' with the actual CSV file name in the dataset\ntrain = '/kaggle/input/f1nalyze-datathon-ieeecsmuj/train.csv'\ntrain_ = pd.read_csv(train)\n\n# Display the first few rows of the DataFrame\ntrain_.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T19:34:38.560974Z","iopub.execute_input":"2024-06-28T19:34:38.561569Z","iopub.status.idle":"2024-06-28T19:35:20.736816Z","shell.execute_reply.started":"2024-06-28T19:34:38.561534Z","shell.execute_reply":"2024-06-28T19:35:20.735708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-28T19:37:10.963891Z","iopub.execute_input":"2024-06-28T19:37:10.964375Z","iopub.status.idle":"2024-06-28T19:37:10.972476Z","shell.execute_reply.started":"2024-06-28T19:37:10.964334Z","shell.execute_reply":"2024-06-28T19:37:10.971292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = '/kaggle/input/f1nalyze-datathon-ieeecsmuj/test.csv'\ntest_ = pd.read_csv(test)\n\n# Display the first few rows of the DataFrame\ntest_.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T19:38:26.975666Z","iopub.execute_input":"2024-06-28T19:38:26.976072Z","iopub.status.idle":"2024-06-28T19:38:31.860135Z","shell.execute_reply.started":"2024-06-28T19:38:26.976041Z","shell.execute_reply":"2024-06-28T19:38:31.859006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-28T19:38:37.928355Z","iopub.execute_input":"2024-06-28T19:38:37.928731Z","iopub.status.idle":"2024-06-28T19:38:37.936362Z","shell.execute_reply.started":"2024-06-28T19:38:37.928703Z","shell.execute_reply":"2024-06-28T19:38:37.935038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation = '/kaggle/input/f1nalyze-datathon-ieeecsmuj/test.csv'\nvalidation_ = pd.read_csv(validation)\n\n# Display the first few rows of the DataFrame\nvalidation_.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-28T19:39:51.718448Z","iopub.execute_input":"2024-06-28T19:39:51.718841Z","iopub.status.idle":"2024-06-28T19:39:55.344678Z","shell.execute_reply.started":"2024-06-28T19:39:51.718803Z","shell.execute_reply":"2024-06-28T19:39:55.343438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-06-28T19:41:11.625086Z","iopub.execute_input":"2024-06-28T19:41:11.625514Z","iopub.status.idle":"2024-06-28T19:41:11.630923Z","shell.execute_reply.started":"2024-06-28T19:41:11.625479Z","shell.execute_reply":"2024-06-28T19:41:11.629764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport os\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load the datasets\ntrain = pd.read_csv('/kaggle/input/f1nalyze-datathon-ieeecsmuj/train.csv')\ntest = pd.read_csv('/kaggle/input/f1nalyze-datathon-ieeecsmuj/test.csv')\nvalidation = pd.read_csv('/kaggle/input/f1nalyze-datathon-ieeecsmuj/validation.csv')\ntrain = train[:1000]\ntest = test[:1000]\nvalidation = validation[:1000]\n\n# Display the first few rows of each DataFrame\nprint(\"Train Data:\")\nprint(train.head())\n\nprint(\"\\nTest Data:\")\nprint(test.head())\n\nprint(\"\\nValidation Data:\")\nprint(validation.head())\n\n# Check for missing values\nprint(\"\\nMissing values in Train Data:\")\nprint(train.isnull().sum())\n\nprint(\"\\nMissing values in Test Data:\")\nprint(test.isnull().sum())\n\nprint(\"\\nMissing values in Validation Data:\")\nprint(validation.isnull().sum())\n\n# Convert non-numeric values to NaN and handle them\ntrain.replace('\\\\N', np.nan, inplace=True)\ntest.replace('\\\\N', np.nan, inplace=True)\nvalidation.replace('\\\\N', np.nan, inplace=True)\n\n# Convert columns to appropriate data types\ntrain = train.apply(pd.to_numeric, errors='ignore')\ntest = test.apply(pd.to_numeric, errors='ignore')\nvalidation = validation.apply(pd.to_numeric, errors='ignore')\n\n# Fill missing values (can also use other strategies like mean/median imputation)\ntrain.fillna(method='ffill', inplace=True)\ntest.fillna(method='ffill', inplace=True)\nvalidation.fillna(method='ffill', inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T06:11:20.68634Z","iopub.execute_input":"2024-06-29T06:11:20.686772Z","iopub.status.idle":"2024-06-29T06:12:16.905665Z","shell.execute_reply.started":"2024-06-29T06:11:20.686739Z","shell.execute_reply":"2024-06-29T06:12:16.904247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the distribution of the target variable (positionOrder) in the train set\nsns.histplot(train['positionOrder'], bins=20, kde=True)\nplt.title('Distribution of Finishing Positions')\nplt.xlabel('Finishing Position')\nplt.ylabel('Frequency')\nplt.show()\n\n# Visualize the correlation matrix for numeric columns only\nnumeric_cols = train.select_dtypes(include=[np.number]).columns\ncorr_matrix = train[numeric_cols].corr()\nplt.figure(figsize=(15, 10))\nsns.heatmap(corr_matrix, annot=True, fmt=\".2f\")\nplt.title('Correlation Matrix')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T06:12:31.587318Z","iopub.execute_input":"2024-06-29T06:12:31.587745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Engineering: Creating new features from existing columns\ntrain['grid_position_diff'] = train['grid'] - train['positionOrder']\ntest['grid_position_diff'] = test['grid'] - test['positionOrder']\nvalidation['grid_position_diff'] = validation['grid'] - validation['positionOrder']\n\n# Select relevant features for modeling\nfeatures = ['racerId', 'driverId', 'constructorId', 'grid', 'points', 'grid_position_diff']\ntarget = 'positionOrder'\n\nX_train = train[features]\ny_train = train[target]\n\nX_test = test[features]\nX_val = validation[features]\ny_val = validation[target]\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T06:12:43.810075Z","iopub.execute_input":"2024-06-29T06:12:43.810484Z","iopub.status.idle":"2024-06-29T06:12:43.823905Z","shell.execute_reply.started":"2024-06-29T06:12:43.810454Z","shell.execute_reply":"2024-06-29T06:12:43.822679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Split the training data into training and validation sets\nX_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n# Initialize a Random Forest Regressor\nrf = RandomForestRegressor(random_state=42)\n\n# Define the parameter grid for GridSearchCV\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\n# Perform Grid Search with Cross-Validation\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\ngrid_search.fit(X_train_split, y_train_split)\n\n# Get the best model\nbest_rf = grid_search.best_estimator_\n\n# Evaluate the model\ny_train_pred = best_rf.predict(X_train_split)\ny_val_pred = best_rf.predict(X_val_split)\n\ntrain_rmse = np.sqrt(mean_squared_error(y_train_split, y_train_pred))\nval_rmse = np.sqrt(mean_squared_error(y_val_split, y_val_pred))\n\nprint(f\"Training RMSE: {train_rmse}\")\nprint(f\"Validation RMSE: {val_rmse}\")\n\n# Test set predictions\ny_test_pred = best_rf.predict(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T06:12:53.694804Z","iopub.execute_input":"2024-06-29T06:12:53.695215Z","iopub.status.idle":"2024-06-29T06:14:05.902213Z","shell.execute_reply.started":"2024-06-29T06:12:53.695184Z","shell.execute_reply":"2024-06-29T06:14:05.900601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the validation set\nval_rmse = np.sqrt(mean_squared_error(y_val, y_test_pred))\nprint(f\"Test RMSE: {val_rmse}\")\n\n# Save the predictions for submission\nsubmission = pd.DataFrame({'resultId': test['resultId'], 'predicted_positionOrder': y_test_pred})\nsubmission.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T06:17:11.93743Z","iopub.execute_input":"2024-06-29T06:17:11.938647Z","iopub.status.idle":"2024-06-29T06:17:11.953387Z","shell.execute_reply.started":"2024-06-29T06:17:11.938603Z","shell.execute_reply":"2024-06-29T06:17:11.95191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}